{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "\n",
    "The neural networks we tried above were all constructed with fully connected layers, or dense layers. That is, each node in a layer connects to every node in the subsequent layer. It is expensive and slow to train a dense model. Convolutional Neural Network (CNN) is a kind of neural network initially developed for image classification, and later applied to learning tasks in other fields. CNN uses filters to scan across the input domain and learn multiple distinct features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.datasets import reuters, mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D CNN \n",
    "\n",
    "2-dimensional convolutional neural networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D CNN\n",
    "1-dimensional convolutional neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_newswire(example):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            List of word indices \n",
    "        Returns:\n",
    "            List of words matched to given indices\n",
    "    \"\"\"\n",
    "    word_to_index = reuters.get_word_index()\n",
    "    index_to_word = {key: value for (value, key) in word_to_index.items()}\n",
    "    words = [index_to_word.get(i-3, 'UNK') for i in example] #indices offset by 3\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_newswire(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_label), (test_data, test_label) = reuters.load_data(num_words=max_features)\n",
    "print(len(train_data), 'train sequences')\n",
    "print(len(test_data), 'test sequences')\n",
    "\n",
    "X_train = sequence.pad_sequences(train_data, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(test_data, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "y_train = keras.utils.to_categorical(train_label, num_classes)\n",
    "y_test = keras.utils.to_categorical(test_label, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (8982, 250)\n",
      "x_test shape: (2246, 250)\n",
      "Build model...\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/10\n",
      "8083/8083 [==============================] - 141s 17ms/step - loss: 1.9266 - acc: 0.5288 - val_loss: 1.4285 - val_acc: 0.6741\n",
      "Epoch 2/10\n",
      "8083/8083 [==============================] - 144s 18ms/step - loss: 1.1318 - acc: 0.7278 - val_loss: 1.1420 - val_acc: 0.7330\n",
      "Epoch 3/10\n",
      "8083/8083 [==============================] - 143s 18ms/step - loss: 0.7258 - acc: 0.8186 - val_loss: 1.0746 - val_acc: 0.7542\n",
      "Epoch 4/10\n",
      "8083/8083 [==============================] - 174s 22ms/step - loss: 0.4568 - acc: 0.8836 - val_loss: 1.1176 - val_acc: 0.7531\n",
      "Epoch 5/10\n",
      "8083/8083 [==============================] - 190s 23ms/step - loss: 0.3231 - acc: 0.9234 - val_loss: 1.0547 - val_acc: 0.7697\n",
      "Epoch 6/10\n",
      "8083/8083 [==============================] - 188s 23ms/step - loss: 0.2483 - acc: 0.9475 - val_loss: 1.1180 - val_acc: 0.7653\n",
      "Epoch 7/10\n",
      "8083/8083 [==============================] - 170s 21ms/step - loss: 0.1990 - acc: 0.9558 - val_loss: 1.0508 - val_acc: 0.7720\n",
      "Epoch 8/10\n",
      "8083/8083 [==============================] - 183s 23ms/step - loss: 0.1749 - acc: 0.9586 - val_loss: 1.0987 - val_acc: 0.7620\n",
      "Epoch 9/10\n",
      "8083/8083 [==============================] - 161s 20ms/step - loss: 0.1720 - acc: 0.9571 - val_loss: 1.1167 - val_acc: 0.7686\n",
      "Epoch 10/10\n",
      "8083/8083 [==============================] - 148s 18ms/step - loss: 0.1423 - acc: 0.9594 - val_loss: 1.1494 - val_acc: 0.7720\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters:\n",
    "max_features = 10000\n",
    "maxlen = 250\n",
    "batch_size = 64\n",
    "embedding_dims = 300\n",
    "filters = 128\n",
    "kernel_size = 9\n",
    "hidden_dims = 512\n",
    "epochs = 10\n",
    "num_classes = 46 \n",
    "\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# begin with embedding layer \n",
    "model.add(Embedding(max_features, embedding_dims, input_length=maxlen))\n",
    "\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 10s 5ms/step\n",
      "Test score: 1.092046438108463\n",
      "Test accuracy: 0.7760463045944832\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
