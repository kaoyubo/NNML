{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "\n",
    "<br>\n",
    "\n",
    "The ANN in previous notebooks were all constructed with fully connected layers, or dense layers. That is, each node in a layer connects to every node in the subsequent layer. For image classification tasks, the number of parameters needed to learn an ANN with dense layers are often millions. Convolutional Neural Networks (CNN) use convolution filters to scan across input space and learn multiple distinct features. CNN is locally connected, each node only connects to a subset of nodes in the subsequent layer. The total number of parameters needed for training is much lower than that of a fully connected neural network, and is much easier to train. CNN was initially developed for computer visions tasks, and later applied to other fields. \n",
    "\n",
    "There are a few main steps for constructing CNN:\n",
    "1. convolution\n",
    "2. nonlinear activation\n",
    "3. max-pooling\n",
    "4. classification\n",
    "\n",
    "Each step is crucial to carry out a learning task. The convolution step can be braodly interpreted as edge detection, and max-pooling can viewed as sampling/dimension reduction. As we go through one convolution layer after another, learned edges can be combined into shapes to become representations of class labels. Below code example is adapted from https://github.com/keras-team/keras/tree/master/examples.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "#input image dimensions\n",
    "img_rows, img_cols = 28, 28 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#normalize input to ensure activation function is effective\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model from Scratch\n",
    "\n",
    "To train a Covolutional Neural Network we:\n",
    " 1. Define architechture of CNN model.  \n",
    " 2. ReLu is default activation function for CNN. \n",
    " 3. Dropout can be added to avoid overfitting.  \n",
    " 4. The last layer is most often a Dense layer. \n",
    " 5. Train model, adjust hyperparameters such as epoch, filter size, stride, optimization. \n",
    " 6. Repeat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "              optimizer=keras.optimizers.Adadelta(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall MNIST dataset is a relatively easy classification task. The hand-written digits in images were centered, and there is no other objects in the images. A comparison of classify MNIST dataset using different algorithms http://yann.lecun.com/exdb/mnist/. Most of the top performing algorithms are CNN. The full power of CNN are better seen from [ImageNet](https://en.wikipedia.org/wiki/ImageNet) classification tasks. The best deep learning models that achieved high accuracy include VGG16, Inception, ResNet, etc., which all used convolutional filters but with different network structure.     \n",
    "\n",
    "### References\n",
    "\n",
    "http://cs231n.github.io/convolutional-networks/\n",
    "\n",
    "http://colah.github.io/posts/2014-07-Conv-Nets-Modular/\n",
    "\n",
    "http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
