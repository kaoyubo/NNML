{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuters Newswire Dataset \n",
    "<br>\n",
    "A collection of newswire data is assembled for text classification purposes, and full description of the dataset can be found at [UCI machine learning repositoty](https://archive.ics.uci.edu/ml/datasets/reuters-21578+text+categorization+collection). Load data to jupyter notebook with Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters \n",
    "\n",
    "n = 10000  # top 10000 most common words\n",
    "\n",
    "(train_data, train_label), (test_data, test_label) = reuters.load_data(num_words=n)\n",
    "print('Number of training examples: ', train_data.shape[0])\n",
    "print('Number of test examples: ', test_data.shape[0])\n",
    "\n",
    "print('Example training data: ', train_data[0])\n",
    "print('Example training data label: ', train_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode Data to Newswire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_newswire(example):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            List of word indices \n",
    "        Returns:\n",
    "            List of words matched to given indices\n",
    "    \"\"\"\n",
    "    word_to_index = reuters.get_word_index()\n",
    "    index_to_word = {key: value for (value, key) in word_to_index.items()}\n",
    "    words = [index_to_word.get(i-3, 'UNK') for i in example] #indices offset by 3\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print one example newswire\n",
    "decode_newswire(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of exmples for each topic label: ', Counter(train_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing \n",
    "\n",
    "All observations in traning dataset are lists of word indices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Vectorized Input Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_input_vectors(X, N):\n",
    "    \"\"\"vectorize newswire data\"\"\"\n",
    "    input = np.zeros((X.shape[0], N))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(len(X[i])):\n",
    "            input[i][X[i][j]] = 1\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = construct_input_vectors(train_data, n)\n",
    "y_train = train_label\n",
    "X_test = construct_input_vectors(test_data, n)\n",
    "y_test = test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = pd.get_dummies(train_label).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Construct Neural Network \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_activation(X, W, b):\n",
    "    Z = np.maximum(np.dot(X, W) + b, 0) # element-wise max between two arrays\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(A):\n",
    "    exps = np.exp(A - np.max(A, axis=1, keepdims=True)) # prevent overflow\n",
    "    return exps / np.sum(exps, axis=1, keepdims=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(model_output, target):\n",
    "    ce = -np.sum(target * np.log(model_output) + (1 - target) * np.log(1 - model_output))\n",
    "    return ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(delta, X):  \n",
    "    gradient = np.dot(X.T, delta)\n",
    "    gradient[X < 0] = 0\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(y, X, W1, b1, W2, b2):\n",
    "    A1 = relu_activation(X, W1, b1)\n",
    "    class_prob = np.dot(A1, W2) + b2\n",
    "    pred = np.argmax(class_prob, axis=1)\n",
    "    print('prediction accuracy: %.2f%%' % (100 * np.mean(pred == y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 100 # size of hidden layer\n",
    "num_classes = 46 # number of classes\n",
    "batch_size = 100 #X_train.shape[0]\n",
    "num_batches = int(X_train.shape[0] / batch_size) + 1 \n",
    "learning_rate = 1\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters \n",
    "np.random.seed(0)\n",
    "\n",
    "W1 = 0.01 * np.random.randn(n, h)\n",
    "b1 = np.zeros((1, h))\n",
    "W2 = 0.01 * np.random.randn(h, num_classes)\n",
    "b2 = np.zeros((1, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch gradient descent \n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    for j in range(num_batches):\n",
    "        \n",
    "        X_batch = X_train[j*batch_size : (j+1)*batch_size:, :]\n",
    "        y_batch = y_train[j*batch_size : (j+1)*batch_size:]\n",
    "        \n",
    "        # forward propogation\n",
    "        A1 = relu_activation(X_batch, W1, b1) \n",
    "        A2 = np.dot(A1, W2) + b2\n",
    "        probs = softmax(A2)  \n",
    "\n",
    "        # cross entropy loss for target\n",
    "        target_logprob = -np.log(probs[range(batch_size), y_batch])\n",
    "        loss = np.sum(target_logprob) / batch_size\n",
    "\n",
    "        # compute the gradient on scores\n",
    "        d2 = probs\n",
    "        d2[range(batch_size), y_batch] -= 1\n",
    "        d2 /= batch_size\n",
    "\n",
    "        # backprop W2 b2\n",
    "        dW2 = np.dot(A1.T, d2)\n",
    "        db2 = np.sum(d2, axis=0, keepdims=True)\n",
    "\n",
    "        # backprop into hidden layer\n",
    "        d1 = np.dot(d2, W2.T)\n",
    "        d1[A1 <= 0] = 0\n",
    "\n",
    "        # backprop W1 b1\n",
    "        dW1 = np.dot(X_batch.T, d1)\n",
    "        db1 = np.sum(d1, axis=0, keepdims=True)\n",
    "\n",
    "        # update weights\n",
    "        W1 -= learning_rate * dW1\n",
    "        b1 -= learning_rate * db1\n",
    "        W2 -= learning_rate * dW2\n",
    "        b2 -= learning_rate * db2\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"epoch {0}: loss {1}\".format(i, loss)) \n",
    "            # evaluate training set accuracy\n",
    "            evaluate_accuracy(y_train, X_train, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate test set accuracy\n",
    "evaluate_accuracy(y_test, X_test, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
