{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuters Newswire Dataset \n",
    "<br>\n",
    "A collection of newswire data is assembled for text classification purposes, and full description of the dataset can be found at [UCI machine learning repositoty](https://archive.ics.uci.edu/ml/datasets/reuters-21578+text+categorization+collection). Load data to jupyter notebook with Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:  8982\n",
      "Number of test examples:  2246\n",
      "Example training data:  [1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "Example training data label:  3\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters \n",
    "\n",
    "n = 10000  # top 10000 most common words\n",
    "\n",
    "(train_data, train_label), (test_data, test_label) = reuters.load_data(num_words=n)\n",
    "print('Number of training examples: ', train_data.shape[0])\n",
    "print('Number of test examples: ', test_data.shape[0])\n",
    "\n",
    "print('Example training data: ', train_data[0])\n",
    "print('Example training data label: ', train_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode Data to Newswire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_newswire(example):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            List of word indices \n",
    "        Returns:\n",
    "            List of words matched to given indices\n",
    "    \"\"\"\n",
    "    word_to_index = reuters.get_word_index()\n",
    "    index_to_word = dict([(key, value) for (value, key) in word_to_index.items()]) \n",
    "    words = [index_to_word.get(i-3, 'UNK') for i in example] #indices offset by 3\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UNK UNK UNK said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print one example newswire\n",
    "decode_newswire(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of exmples for each topic label:  Counter({3: 3159, 4: 1949, 19: 549, 16: 444, 1: 432, 11: 390, 20: 269, 13: 172, 8: 139, 10: 124, 9: 101, 21: 100, 25: 92, 2: 74, 18: 66, 24: 62, 0: 55, 34: 50, 12: 49, 36: 49, 28: 48, 6: 48, 30: 45, 23: 41, 31: 39, 17: 39, 40: 36, 32: 32, 41: 30, 14: 26, 26: 24, 39: 24, 43: 21, 15: 20, 38: 19, 37: 19, 29: 19, 45: 18, 5: 17, 7: 16, 27: 15, 22: 15, 42: 13, 44: 12, 33: 11, 35: 10})\n"
     ]
    }
   ],
   "source": [
    "print('Number of exmples for each topic label: ', Counter(train_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing \n",
    "\n",
    "All observations in traning dataset are lists of word indices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Vectorized Input Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_input_vectors(X, N):\n",
    "    \"\"\"vectorize newswire data\"\"\"\n",
    "    input = np.zeros((X.shape[0], N))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(len(X[i])):\n",
    "            input[i][X[i][j]] = 1\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = construct_input_vectors(train_data, n)\n",
    "y_train = train_label\n",
    "X_test = construct_input_vectors(test_data, n)\n",
    "y_test = test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = pd.get_dummies(train_label).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Construct Neural Network \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_activation(X, W, b):\n",
    "    Z = np.maximum(np.dot(X, W) + b, 0) # element-wise max between two arrays\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(A):\n",
    "    exps = np.exp(A - np.max(A, axis=1, keepdims=True)) # prevent overflow\n",
    "    return exps / np.sum(exps, axis=1, keepdims=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(model_output, target):\n",
    "    ce = -np.sum(target * np.log(model_output) + (1 - target) * np.log(1 - model_output))\n",
    "    return ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(delta, X):  \n",
    "    gradient = np.dot(X.T, delta)\n",
    "    gradient[X < 0] = 0\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(y, X, W1, b1, W2, b2):\n",
    "    A1 = relu_activation(X, W1, b1)\n",
    "    class_prob = np.dot(A1, W2) + b2\n",
    "    pred = np.argmax(class_prob, axis=1)\n",
    "    print('prediction accuracy: %.2f%%' % (100 * np.mean(pred == y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 100 # size of hidden layer\n",
    "num_classes = 46 # number of classes\n",
    "batch_size = X_train.shape[0]\n",
    "learning_rate = 1\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters \n",
    "np.random.seed(0)\n",
    "\n",
    "W1 = 0.01 * np.random.randn(n, h)\n",
    "b1 = np.zeros((1, h))\n",
    "W2 = 0.01 * np.random.randn(h, num_classes)\n",
    "b2 = np.zeros((1, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: loss 3.8271235620616832\n",
      "prediction accuracy: 2.55%\n",
      "epoch 10: loss 2.305714185084428\n",
      "prediction accuracy: 35.17%\n",
      "epoch 20: loss 1.8440828770181341\n",
      "prediction accuracy: 52.48%\n",
      "epoch 30: loss 1.5867835288424288\n",
      "prediction accuracy: 60.70%\n",
      "epoch 40: loss 1.4334826360898312\n",
      "prediction accuracy: 67.96%\n",
      "epoch 50: loss 1.2946896739726377\n",
      "prediction accuracy: 70.17%\n",
      "epoch 60: loss 1.2125398928937663\n",
      "prediction accuracy: 70.86%\n",
      "epoch 70: loss 1.1571459581867884\n",
      "prediction accuracy: 71.57%\n",
      "epoch 80: loss 1.0795161375162003\n",
      "prediction accuracy: 73.57%\n",
      "epoch 90: loss 1.0348482956113996\n",
      "prediction accuracy: 74.74%\n"
     ]
    }
   ],
   "source": [
    "# batch gradient descent \n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    # forward propogation\n",
    "    A1 = relu_activation(X_train, W1, b1) \n",
    "    A2 = np.dot(A1, W2) + b2\n",
    "    probs = softmax(A2)  \n",
    "    \n",
    "    # compute cross entropy loss \n",
    "    corect_logprobs = -np.log(probs[range(batch_size), y_train])\n",
    "    loss = np.sum(corect_logprobs) / batch_size\n",
    "  \n",
    "    if i % 10 == 0:\n",
    "        print(\"epoch {0}: loss {1}\".format(i, loss)) \n",
    "        # evaluate training set accuracy\n",
    "        evaluate_accuracy(y_train, X_train, W1, b1, W2, b2)\n",
    "     \n",
    "    # compute the gradient on scores\n",
    "    dscores = probs\n",
    "    dscores[range(batch_size), y_train] -= 1\n",
    "    dscores /= batch_size\n",
    "      \n",
    "    # backprop W2 b2\n",
    "    dW2 = np.dot(A1.T, dscores)\n",
    "    db2 = np.sum(dscores, axis=0, keepdims=True)\n",
    "    \n",
    "    # backprop into hidden layer\n",
    "    dhidden = np.dot(dscores, W2.T)\n",
    "    dhidden[A1 <= 0] = 0\n",
    "    \n",
    "    # backprop W1 b1\n",
    "    dW1 = np.dot(X_train.T, dhidden)\n",
    "    db1 = np.sum(dhidden, axis=0, keepdims=True)\n",
    "  \n",
    "    # update weights\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction accuracy: 71.37%\n"
     ]
    }
   ],
   "source": [
    "# evaluate test set accuracy\n",
    "evaluate_accuracy(y_test, X_test, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
