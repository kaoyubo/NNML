{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset \n",
    "<br>\n",
    "MNIST is a collection of handwritten digits saved in 28-by-28 pixels images. Datasets for training and testing can be downloaded at https://www.kaggle.com/c/digit-recognizer/data. Each row of the training data are the pixel values (0-255) for one handwritten digit image. We can use similar procedures as above XOR example to construct our neural network, and change only the number of input nodes, hidden nodes, and output nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Batch vs Online Learning\n",
    "If we update weights after we calculated erorr for all training data, then it is called batch learning. There are several advantages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "# we use sigmoid activation function throughout the workbook\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot 20 example figuures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load some data and plot 20 sample images for view \n",
    "with open('train.csv', 'r') as f:\n",
    "    # skip header row in csv file\n",
    "    data = f.readlines()[1:21]\n",
    "\n",
    "plt.figure(figsize=(15,1)) \n",
    "for i in range(20):\n",
    "    plt.subplot(1, 20, i)\n",
    "    # split pixel values by comma\n",
    "    values = data[i].split(',') \n",
    "    # convert string to float and reshape matrix\n",
    "    pixels = np.asfarray(values[1:]).reshape((28, 28))\n",
    "    # plot in grayscale\n",
    "    plt.imshow(pixels, cmap='Greys')\n",
    "    # no ticks\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load training dataset in pandas dataframe for manipulation\n",
    "df = pd.read_csv('train.csv', sep=',',header=0)\n",
    "\n",
    "# get pixel values for each image and convert to numpy array\n",
    "X = df.iloc[:,1:].as_matrix()\n",
    "# normalize pixel values to between 0 and 1 \n",
    "X = X / 255.0  \n",
    "\n",
    "# first element of each row is the label \n",
    "label = df.iloc[:,0]\n",
    "# set up target array of 10 nodes for all 10 classes \n",
    "y = np.zeros((df.shape[0], 10))\n",
    "# set node for the correct label to 1 and keep others 0\n",
    "for i in range(df.shape[0]):\n",
    "    y[i, label[i]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "# number of hidden nodes\n",
    "num_nodes = 200\n",
    "# number of records in training set\n",
    "num_train = 40000\n",
    "\n",
    "X_train = X[:num_train,:]\n",
    "y_train = y[:num_train,:]\n",
    "W1 = 0.01 * np.random.randn(X.shape[1], num_nodes) # dim (784, N)\n",
    "W2 = 0.01 * np.random.randn(num_nodes, 10) # dim (N, 10)\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    \n",
    "    # go through all records \n",
    "    for X_online, y_online in zip(X_train, y_train):        \n",
    "        \n",
    "        # each record has to be a 2D array \n",
    "        X_online = np.array([X_online]) \n",
    "        y_online = np.array([y_online])\n",
    "        \n",
    "        # forward propagation \n",
    "        z1 = sigmoid(np.dot(X_online, W1))    \n",
    "        z2 = sigmoid(np.dot(z1, W2)) \n",
    "\n",
    "        # backward propagation\n",
    "        z2_delta = (z2 - y_online) * z2 * (1.0 - z2) \n",
    "        z2_gradient = np.dot(z1.T, z2_delta) \n",
    "        z1_delta = np.dot(z2_delta, W2.T) * z1 * (1.0 - z1) \n",
    "        z1_gradient = np.dot(X_online.T, z1_delta) \n",
    "\n",
    "        # update weights\n",
    "        W2 -= learning_rate * z2_gradient\n",
    "        W1 -= learning_rate * z1_gradient \n",
    "           \n",
    "    z2 = sigmoid(np.dot(sigmoid(np.dot(X_train, W1)), W2)) \n",
    "    loss = np.around(0.5 * np.sum((z2 - y_train)**2) / num_train, decimals=5) \n",
    "    print \"Average squared difference between output and target at epoch {} : {}\".format(i + 1, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = X[num_train:,:]\n",
    "y_test = label[num_train:]\n",
    "predict = np.argmax(sigmoid(np.dot(sigmoid(np.dot(X_test, W1)), W2)), axis=1)\n",
    "accuracy = 100.0 * sum(predict == y_test) / (42000 - num_train)\n",
    "print 'prediction accuracy: %.2f%%' % round(accuracy, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
